{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec8fc8f-771e-463a-b784-5b79d2e473b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4d58ad-72bc-44c9-979d-acbe24f8fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1599, 12)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Data\n",
    "try:\n",
    "    df = pd.read_csv(\"Part- 123 - Signal.csv\")\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Data Cleaning\n",
    "# Drop columns with >20% missing values\n",
    "df.dropna(axis=1, thresh=0.8 * len(df), inplace=True)\n",
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "# Remove irrelevant columns (Assume first column is timestamp)\n",
    "df.drop(columns=[df.columns[0]], inplace=True)  # Adjust if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01998474-62aa-4894-a88d-bfe4958a0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Preprocessing\n",
    "X = df.drop(columns=['Parameter 2']) # Predictors\n",
    "y = df['Signal_Strength'] # Target variable\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a419108-c8d9-4e3b-b6c2-9aa0404b4703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef71dfc0-9c75-47c0-b8bf-49e4783722d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n",
      "Training SVM...\n",
      "Training NaiveBayes...\n"
     ]
    }
   ],
   "source": [
    "#Step 4 : Model Training And Hyper Training \n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"RandomForest\": {\"n_estimators\": [100, 200], \"max_depth\": [10, 30, None]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]},\n",
    "    \"NaiveBayes\": {}\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    if params[model_name]:\n",
    "        grid = GridSearchCV(model, params[model_name], cv=5, n_jobs=-1, scoring='accuracy')\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_models[model_name] = grid.best_estimator_\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        best_models[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "680dcd4a-d4f6-4d82-8e7c-ea99fdd490bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      1.00      1.00       122\n",
      "           4       1.00      1.00      1.00        98\n",
      "           5       1.00      1.00      1.00       128\n",
      "           6       1.00      1.00      1.00       115\n",
      "           7       1.00      1.00      1.00       120\n",
      "           8       1.00      1.00      1.00       110\n",
      "\n",
      "    accuracy                           1.00       693\n",
      "   macro avg       1.00      1.00      1.00       693\n",
      "weighted avg       1.00      1.00      1.00       693\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      1.00      1.00       122\n",
      "           4       1.00      1.00      1.00        98\n",
      "           5       1.00      1.00      1.00       128\n",
      "           6       1.00      1.00      1.00       115\n",
      "           7       1.00      1.00      1.00       120\n",
      "           8       1.00      1.00      1.00       110\n",
      "\n",
      "    accuracy                           1.00       693\n",
      "   macro avg       1.00      1.00      1.00       693\n",
      "weighted avg       1.00      1.00      1.00       693\n",
      "\n",
      "Accuracy: 1.0000\n",
      "\n",
      "NaiveBayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      1.00      1.00       122\n",
      "           4       1.00      1.00      1.00        98\n",
      "           5       1.00      1.00      1.00       128\n",
      "           6       1.00      1.00      1.00       115\n",
      "           7       1.00      1.00      1.00       120\n",
      "           8       1.00      1.00      1.00       110\n",
      "\n",
      "    accuracy                           1.00       693\n",
      "   macro avg       1.00      1.00      1.00       693\n",
      "weighted avg       1.00      1.00      1.00       693\n",
      "\n",
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Model Evaluation\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "199a79de-c9a8-4dde-b7e5-465edb629594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Save the Best Model\n",
    "best_model = max(best_models.items(), key=lambda x: accuracy_score(y_test, x[1].predict(X_test)))[1]\n",
    "joblib.dump(best_model, \"best_semiconductor_model.pkl\")\n",
    "print(\"Best Model Saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699745ee-ba83-4ccc-8d01-5619d48b575d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
